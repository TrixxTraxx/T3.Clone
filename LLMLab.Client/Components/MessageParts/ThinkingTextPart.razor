@using LLMLab.Client.Caches
<div class="thinking-response @(IsThinkingCollapsed ? "collapsed" : "")">
    <div class="thinking-header" @onclick="ToggleThinkingDisplay">
        <div class="thinking-icon">
            <svg viewBox="0 0 24 24" fill="currentColor">
                <path d="M12 2L13.09 8.26L20 9L13.09 9.74L12 16L10.91 9.74L4 9L10.91 8.26L12 2Z"/>
            </svg>
        </div>
        <span class="thinking-label">Thinking</span>
        <div class="thinking-toggle @(IsThinkingCollapsed ? "collapsed" : "")">
            <svg viewBox="0 0 24 24" fill="currentColor">
                <path d="M7 10L12 15L17 10H7Z"/>
            </svg>
        </div>
    </div>
    @if (!IsThinkingCollapsed)
    {
        <div class="thinking-content">
            <div class="thinking-text">
                <MarkdownTextPart @ref="markdownText" Content="@Message.Message.ThinkingResponse" Message="Message"></MarkdownTextPart>
            </div>
        </div>
    }
</div>

@code {
    [Parameter] public MessageCache Message { get; set; } = new();
    [Parameter] public bool IsThinkingCollapsed { get; set; }
    [Parameter] public EventCallback<bool> IsThinkingCollapsedChanged { get; set; }
    private MarkdownTextPart markdownText;

    private async Task ToggleThinkingDisplay()
    {
        IsThinkingCollapsed = !IsThinkingCollapsed;
        await IsThinkingCollapsedChanged.InvokeAsync(IsThinkingCollapsed);
    }


    public async Task SetThinkingCollapsed(bool collapsed)
    {
        if (IsThinkingCollapsed != collapsed)
        {
            await ToggleThinkingDisplay();
        }
    }
    
    public void OnTokenReceived(string token)
    {
        InvokeAsync(async () =>
        {
            await markdownText.OnTokenReceived(Message.Message.ThinkingResponse);
        });
    }

} 